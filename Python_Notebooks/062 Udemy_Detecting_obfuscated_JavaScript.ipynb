{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Udemy Detecting obfuscated JavaScript.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sb59ySurCEZ"
      },
      "source": [
        "We will see how to use machine learning to detect when a JavaScript file is obfuscated"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f340x1MRoFBk",
        "outputId": "a78a586e-f586-4b1a-f3c4-8c341444cdf5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0QCkjcuqqwb",
        "outputId": "36a60541-fcfb-4e07-89f5-957614b56e24"
      },
      "source": [
        "%cd /content/drive/My Drive/Colab Notebooks"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNWut866rUVE"
      },
      "source": [
        "# We will begin by importing the libraries we will be needint to process the Javascript's content, prepare the dataset, classify it and measure the performance of our classifier\n",
        "import os\n",
        "from sklearn.feature_extraction.text import HashingVectorizer, TfidfTransformer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.pipeline import Pipeline"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VdR8fTdsBXF"
      },
      "source": [
        "# We need to specify the paths of our obfuscated and non-obfuscated Javascript files and assign the two types of file different labels\n",
        "js_path = \"JavascriptSamples\"\n",
        "obfuscated_js_path = \"JavascriptSamplesObfuscated\""
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8UJmf-Ksdl2"
      },
      "source": [
        "corpus=[]\n",
        "labels=[]\n",
        "file_types_and_labels = [(js_path, 0), (obfuscated_js_path, 1)]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axeQxEs-ssip"
      },
      "source": [
        "# We will read our files into a corpus and prepare labels\n",
        "for files_path, label in file_types_and_labels:\n",
        "    files = os.listdir(files_path)\n",
        "    for file in files:\n",
        "        file_path = files_path + \"/\" + file\n",
        "        try:\n",
        "            with open(file_path, \"r\") as myfile:\n",
        "                data = myfile.read().replace(\"\\n\", \"\")\n",
        "                data = str(data)\n",
        "                corpus.append(data)\n",
        "                labels.append(label)\n",
        "        except:\n",
        "            pass"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYyO_rLxy2b6"
      },
      "source": [
        "# We will split our dataset into a training and testing set and prepare a pipeline to perform basic NLP, followed by a random forest classifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test, y_train,y_test = train_test_split(corpus, labels, test_size=0.33, random_state=42)\n",
        "text_clf = Pipeline(\n",
        "    [\n",
        "     (\"vect\", HashingVectorizer(input=\"content\", ngram_range=(1,3))),\n",
        "     (\"tfidf\", TfidfTransformer(use_idf=True,)),\n",
        "     (\"rf\", RandomForestClassifier(class_weight=\"balanced\")),\n",
        "    ]\n",
        ")"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMAylWx3z2DX",
        "outputId": "e9581346-9b33-4e32-97a8-0a05f0e701e7"
      },
      "source": [
        "# We will fit our pipline to training data, predict the testing data and then print the result\n",
        "text_clf.fit(x_train, y_train)\n",
        "y_test_pred = text_clf.predict(x_test)\n",
        "print(accuracy_score(y_test,y_test_pred))\n",
        "print(confusion_matrix(y_test,y_test_pred))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9658886894075404\n",
            "[[610  25]\n",
            " [ 13 466]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyW9BrgT0rso"
      },
      "source": [
        "\n",
        "\n",
        "*   Step 1: We import library and analyze files and set up machine learning.\n",
        "\n",
        "*   Step 2 and 3 we collected the non-obfuscated and obfuscated Javascript files into arrays adn assign them their respective labels. This is a preparation for our classification problem. The main challenge is that producing this classifier is producing a large and useful dataset\n",
        "*   Step 4 we dividide the dataset into a training and testing subset. We also set up the pipline to apply NLP methods to the Javascript code itself and then train a classifier\n",
        "\n",
        "\n",
        "*   Step 5, we measure the performance of our classifier.\n",
        "\n"
      ]
    }
  ]
}