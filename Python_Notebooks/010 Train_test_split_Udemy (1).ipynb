{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Train test split Udemy.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "478ne8Yauv0n"
      },
      "source": [
        "In machine learning, our goal is to create a program that is able to perform tasks it has never been explicitly taught to perform. The way we do is to use data we have collected to train or fit a mathematical or statistical model. The data used to fit the model is called training data.\n",
        "\n",
        "The result of trained model is used to predict the future, previously unseendata. In this way the program is able to manage new situations with out human intervention.\n",
        "\n",
        "Challenge is overfitting which is a model that performs well on the training data but is not able to generalize to new, previously-unseen data.\n",
        "\n",
        "\n",
        "To solve this proplem, machine learning engieers set aside a portion of the data, called test data and use it to assess the performance of the trained model, as opposed to including it as part of the training dataset.\n",
        "\n",
        "Overfitting in cyber security is an omnipresent danger.\n",
        "\n",
        "One small oversight, such as using only benign data from 1 locale, can lead to a poor classifier.\n",
        "\n",
        "There are various other ways to validate model performance, such as cross-validation. For simplicity, we will focus mainly on train-test splitting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLOM1SJp0HcH",
        "outputId": "b7ef1445-1e2c-4e05-849b-5719a3c8e7f6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOnE5xzz0KQl",
        "outputId": "ef14f29b-d4e4-4724-805c-495ddc82f695"
      },
      "source": [
        "%cd /content/drive/My Drive/Colab Notebooks"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqVBlXmg1WBj"
      },
      "source": [
        "# import train_test_split module and the pandas library and read features into x and labels into y.\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as d"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04jwUFPb1mvO"
      },
      "source": [
        "df = pd.read_csv(\"north_korea_missile_test_database.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POfj6rYe1223"
      },
      "source": [
        "y = df[\"Missile Name\"]\n",
        "x = df.drop(\"Missile Name\", axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XgHv3692X8M"
      },
      "source": [
        "# Randomly split the dataset and its labels into a training set consisting 80% of the size of the original dataset and a testing set 20% of the size\n",
        "X_train, X_test, y_train, y_test = train_test_split(x,y,test_size=0.2, random_state = 31)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2Z96h-g2wZM"
      },
      "source": [
        "# We will apply the train_test_split method once more, to obtain a validation set, x_val and y_val\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.25, random_state=31)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPSL4tyT3JjN",
        "outputId": "1809bb3c-75fa-40da-a489-dd1ad3646134"
      },
      "source": [
        "# 60% of the size of the original data, a validation set of 20% and a testing set of 20%\n",
        "print(len(X_train))\n",
        "print(len(y_train))\n",
        "print(len(X_val))\n",
        "print(len(y_val))\n",
        "print(len(X_test))\n",
        "print(len(y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "81\n",
            "81\n",
            "27\n",
            "27\n",
            "27\n",
            "27\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLN72Az53mNw"
      },
      "source": [
        "How does it work\n",
        "\n",
        "\n",
        "*   Step 1: We start by reading our dataset, consisting of historical and continuing missile experiments in North Korea. We aim to predict the type of missile based on remaining features, such as facility and time of launch\n",
        "*   Step 2: we apply the sklearn's train_test_split emthod to subdivide X and y into a training set, X_train and y_train, and also a testing set,X_test and y_test. The test_size = 0.3 parameter means that the testing set consist of 20% of the original data while the remainder is placed in the training set.  The random_state parameter allows us to reproduce the same randomly generated split.\n",
        "\n",
        "*   Step 3: We often compare several different models. The danger of using the testing set is to select the best model is that we may end up overfitting the testing set. This is similar to the statistical sin of data fishing. In order to solve this problem, we need to create an additional dataset called validation set.\n",
        "\n",
        "\n",
        "*   step 4 will be double check our assumptions by employing the len function to compute the length of the array.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}